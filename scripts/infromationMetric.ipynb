{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb57f8d7-383a-419f-a6dd-787f79bd2079",
   "metadata": {},
   "source": [
    "# Information gain metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e6c6bf-321c-480f-8b24-2347e27f22a3",
   "metadata": {},
   "source": [
    "## making structure where infromation gain is easily accessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba21f972-9006-4b88-be86-18758405ce72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from ontobio.ontol_factory import OntologyFactory\n",
    "from ontobio.assoc_factory import AssociationSetFactory\n",
    "import os\n",
    "import json\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82494abc-4969-43e5-88aa-872a55ff8513",
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDER = \"./../data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fbe50d9-d403-4eed-8792-aecb14b6f13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "namespace_list = [\"cellular_component\", \"molecular_function\", \"biological_process\"]\n",
    "\n",
    "#maybe also save the alternative IDs, not sure right now\n",
    "class Node:\n",
    "  def __init__(self, name):\n",
    "    self.name = name\n",
    "    self.visited = False  # for BFS\n",
    "    self.reachable_nodes_count = 1  \n",
    "    self.infromationMetric = 0\n",
    "    self.namespace = -1\n",
    "    #without alternative IDs\n",
    "    self.parents = []  \n",
    "    self.children = []\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32deed15-8523-4285-855f-ecf5b1bee154",
   "metadata": {},
   "source": [
    "For now only checking part_of and is_a relationships. not regulates, positively_regulates and negatively_regulates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1a5de8c-6835-4ba1-bcf1-b7313a5bb381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68896\n",
      "6815\n"
     ]
    }
   ],
   "source": [
    "goFile = open(FOLDER + 'go-basic.obo', 'r')\n",
    "Lines = goFile.readlines()\n",
    "\n",
    "nodeDict = dict()\n",
    "alternative_ID_dict = dict()\n",
    "\n",
    "count_IS_a_relationship = 0\n",
    "count_part_of_relationship = 0\n",
    "lastID  = \"\"\n",
    "altID = []\n",
    "\n",
    "\n",
    "\n",
    "for line in Lines:\n",
    "    #NEW GO term\n",
    "    if line[0:4] == \"id: \":\n",
    "        if altID:\n",
    "            alternative_ID_dict[lastID] = altID\n",
    "        altID = [] \n",
    "        \n",
    "        lastID = line[4:-1]\n",
    "        if not (lastID in nodeDict):\n",
    "            nodeDict[lastID] = Node(lastID)\n",
    "    #when the lastID was checked to be obsolete, then move on, until there is new lastID\n",
    "    if lastID == \"obsolete\":\n",
    "        continue\n",
    "    \n",
    "    #adding namespace\n",
    "\n",
    "    if line[0:10] == \"namespace:\":\n",
    "        namespace = line.split()[1]\n",
    "        for i in range(len(namespace_list)):\n",
    "            if (namespace == namespace_list[i]):\n",
    "                nodeDict[lastID].namespace = i\n",
    "                \n",
    "    #ALternative name for ID\n",
    "    if line[0:8] == \"alt_id: \":\n",
    "        altID.append(line[8:-1])\n",
    "    \n",
    "    #Check if gene is obsolete\n",
    "    if line[0:11] == \"is_obsolete\" :\n",
    "        altID = []\n",
    "        nodeDict.pop(lastID)\n",
    "        lastID = \"obsolete\"\n",
    "        \n",
    "    #IS_a relationship    \n",
    "    if line[0:5] == \"is_a:\":\n",
    "        count_IS_a_relationship +=1\n",
    "        isA = line[5:-1].split()[0]\n",
    "        # TODO check if isA, means that the lastID is a parent of that node, or children\n",
    "        nodeDict[lastID].parents.append(isA)  \n",
    "        if not (isA in nodeDict):\n",
    "            nodeDict[isA] = Node(isA)\n",
    "        nodeDict[isA].children.append(lastID)\n",
    "        \n",
    "    # part_of relationship    \n",
    "    if line[0:21] == \"relationship: part_of\":\n",
    "        count_part_of_relationship +=1\n",
    "        partOf = line[21:-1].split()[0]\n",
    "        # TODO check if isA, means that the lastID is a parent of that node, or children\n",
    "        nodeDict[lastID].parents.append(partOf)  \n",
    "        if not (partOf in nodeDict):\n",
    "            nodeDict[partOf] = Node(partOf)\n",
    "        nodeDict[partOf].children.append(lastID)\n",
    "        \n",
    "    \n",
    "goFile.close()        \n",
    "\n",
    "alternative_ID_dict[lastID] = altID\n",
    "print(count_IS_a_relationship)\n",
    "print(count_part_of_relationship)        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3f0c9c3-93f9-4405-95f8-76f54ad1aec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "#simple test if there is same number of parents as childrens\n",
    "count_children = 0\n",
    "count_parents = 0\n",
    "for ID, node in nodeDict.items():\n",
    "    if node.children:\n",
    "        count_children += len(node.children)\n",
    "    if node.parents:\n",
    "        count_parents += len(node.parents)\n",
    "\n",
    "print(count_children == count_parents)\n",
    "print(count_IS_a_relationship + count_part_of_relationship == count_parents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22742273-bccf-4c37-8fd5-887fcc41a0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing regulates, negatively_regulates,positively_regulates, part_of, term_tracker_item\n",
    "nodes_to_remove = [\"regulates\", \"negatively_regulates\", \"positively_regulates\", \"part_of\", \"term_tracker_item\"]\n",
    "for node in nodes_to_remove:\n",
    "    nodeDict.pop(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "235ca76a-f137-43ab-9228-260665cefd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating root element\n",
    "root = Node(\"root\")\n",
    "for ID, node in nodeDict.items():\n",
    "    if not node.parents:\n",
    "        root.children.append(node.name)\n",
    "        node.parents.append(root.name)\n",
    "        \n",
    "nodeDict[\"root\"] = root\n",
    "numberOfNodes = len(nodeDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67435c42-c679-4d82-99fc-59a397176afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding to the dictionary alternative ID, these points to the same node as the their original ID\n",
    "count_Alt_ID = 0\n",
    "for ID, alt_ID_list in alternative_ID_dict.items():\n",
    "    for alt_ID in alt_ID_list:\n",
    "        if (alt_ID in nodeDict):\n",
    "            count_Alt_ID += 1\n",
    "            \n",
    "        nodeDict[alt_ID] = nodeDict[ID]\n",
    "if count_Alt_ID !=0:\n",
    "    print(\"nieco je zle\") # TEST if the alt_ID is already in nodeDict, if it were, my proccesing of GO would be bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d8fe4ea-43c8-4b0b-ac3f-bf2f22037216",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check visited and change it before usage of BFS\n",
    "def BFS(nodeID, nodeDict):\n",
    "    current_node = nodeDict[nodeID]\n",
    "    for child in current_node.children:\n",
    "        if not nodeDict[child].visited:\n",
    "            nodeDict[child].visited = True\n",
    "            BFS(child, nodeDict)\n",
    "            current_node.reachable_nodes_count += nodeDict[child].reachable_nodes_count\n",
    "\n",
    "BFS(\"root\", nodeDict) \n",
    "#test if bfs is valid\n",
    "root.reachable_nodes_count == numberOfNodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb245dd7-e77f-4244-8de0-192f7126733c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for node in nodeDict.values():\n",
    "    node.infromationMetric = node.reachable_nodes_count / numberOfNodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f9afc09-32bc-4a27-8564-fbbf7dbc092b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6448461502761406\n",
      "0.26131247969554927\n",
      "0.09381816494175524\n"
     ]
    }
   ],
   "source": [
    "#just test\n",
    "for i  in root.children:\n",
    "    print(nodeDict[i].infromationMetric)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a57c8ae-770d-4b5f-ab8f-2ef3b3678fea",
   "metadata": {},
   "source": [
    "## Clustering and metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b852ed2b-dd0e-46b1-8c84-8d1b6a1a0a85",
   "metadata": {},
   "source": [
    "### getting data for clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c652b2de-a48e-4ad9-852e-d1907c3ef791",
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_disease_csv = pd.read_csv(FOLDER+ \"gene_disease_view.csv\")\n",
    "gene_disease_series = gene_disease_csv.groupby([\"geneName\"])[\"diseaseId\"].apply(list)\n",
    "gene_disease_dict = gene_disease_series.to_dict()\n",
    "\n",
    "gene_to_list_of_diseases = []\n",
    "\n",
    "#propably could be improved somehow with pandas functionality\n",
    "for gene_name, disease_ids in gene_disease_dict.items():\n",
    "    new_dict = {'diseaseId': disease_ids, 'geneName': str(gene_name)}\n",
    "    gene_to_list_of_diseases.append(new_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42801b2e-a93a-4d2f-baf6-9331518070e3",
   "metadata": {},
   "source": [
    "### Mapping geneName to GO terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c2b5f004-ae92-4d0e-ac31-517bf4cf1442",
   "metadata": {},
   "outputs": [],
   "source": [
    "#geneName to GO\n",
    "f = open(FOLDER + 'mapping_gene_to_go.json')\n",
    "mapping_geneName_to_GO = json.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7cd933f-b85a-4608-a0b6-3a020031c83b",
   "metadata": {},
   "source": [
    "### Feature extraction and simple clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bc23b294-ed79-48ce-9bed-7428aa4cb4af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 3, ..., 3, 3, 3])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec = DictVectorizer()\n",
    "matrixGeneDisease = vec.fit_transform(gene_to_list_of_diseases)\n",
    "matrixGeneDisease\n",
    "\n",
    "cluster = KMeans()\n",
    "result = cluster.fit(matrixGeneDisease)\n",
    "result.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab3e686-24e4-4044-bfec-3e0689e54cdb",
   "metadata": {},
   "source": [
    "### Creating arrays of geneIdentificators which ont takes , for each cluster. (information metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c44f2187-fb46-47f1-95dc-7bfcd619714f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clustersGO = []\n",
    "for i in range(max(result.labels_) + 1):\n",
    "    clustersGO.append([])\n",
    "\n",
    "for i in range(len(result.labels_)):\n",
    "    if gene_to_list_of_diseases[i][\"geneName\"] in mapping_geneName_to_GO:\n",
    "        clustersGO[result.labels_[i]].append(mapping_geneName_to_GO[gene_to_list_of_diseases[i][\"geneName\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe93233-8e32-44a4-b95a-ad4298a5d04f",
   "metadata": {},
   "source": [
    "### Creating ontology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fe42df08-41e0-4bb6-8477-bbd5fa8f8f2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-08 17:24:53 [WARNING] [PID:14776 TID:2544] [golr_query.py:1804 in `translate_docs_compact`]  >1 relation: ['not', 'contributes_to']\n",
      "2023-05-08 17:24:53 [WARNING] [PID:14776 TID:2544] [golr_query.py:1804 in `translate_docs_compact`]  >1 relation: ['not', 'colocalizes_with']\n",
      "2023-05-08 17:24:54 [WARNING] [PID:14776 TID:2544] [golr_query.py:1804 in `translate_docs_compact`]  >1 relation: ['not', 'colocalizes_with']\n",
      "2023-05-08 17:24:54 [WARNING] [PID:14776 TID:2544] [golr_query.py:1804 in `translate_docs_compact`]  >1 relation: ['not', 'colocalizes_with']\n",
      "2023-05-08 17:24:54 [WARNING] [PID:14776 TID:2544] [golr_query.py:1804 in `translate_docs_compact`]  >1 relation: ['not', 'contributes_to']\n",
      "2023-05-08 17:24:54 [WARNING] [PID:14776 TID:2544] [golr_query.py:1804 in `translate_docs_compact`]  >1 relation: ['not', 'colocalizes_with']\n",
      "2023-05-08 17:24:55 [WARNING] [PID:14776 TID:2544] [golr_query.py:1804 in `translate_docs_compact`]  >1 relation: ['not', 'contributes_to']\n",
      "2023-05-08 17:24:55 [WARNING] [PID:14776 TID:2544] [golr_query.py:1804 in `translate_docs_compact`]  >1 relation: ['not', 'colocalizes_with']\n",
      "2023-05-08 17:24:55 [WARNING] [PID:14776 TID:2544] [golr_query.py:1804 in `translate_docs_compact`]  >1 relation: ['not', 'contributes_to']\n",
      "2023-05-08 17:24:55 [WARNING] [PID:14776 TID:2544] [golr_query.py:1804 in `translate_docs_compact`]  >1 relation: ['not', 'colocalizes_with']\n",
      "2023-05-08 17:24:55 [WARNING] [PID:14776 TID:2544] [golr_query.py:1804 in `translate_docs_compact`]  >1 relation: ['not', 'contributes_to']\n",
      "2023-05-08 17:24:55 [WARNING] [PID:14776 TID:2544] [golr_query.py:1804 in `translate_docs_compact`]  >1 relation: ['not', 'colocalizes_with']\n",
      "2023-05-08 17:24:55 [WARNING] [PID:14776 TID:2544] [golr_query.py:1804 in `translate_docs_compact`]  >1 relation: ['not', 'colocalizes_with']\n",
      "2023-05-08 17:24:56 [WARNING] [PID:14776 TID:2544] [golr_query.py:1804 in `translate_docs_compact`]  >1 relation: ['not', 'colocalizes_with']\n",
      "2023-05-08 17:24:56 [WARNING] [PID:14776 TID:2544] [golr_query.py:1804 in `translate_docs_compact`]  >1 relation: ['not', 'contributes_to']\n",
      "2023-05-08 17:24:56 [WARNING] [PID:14776 TID:2544] [golr_query.py:1804 in `translate_docs_compact`]  >1 relation: ['not', 'contributes_to']\n"
     ]
    }
   ],
   "source": [
    "HUMAN = 'NCBITaxon:9606'\n",
    "PART_OF = 'BFO:0000050'\n",
    "\n",
    "ofactory = OntologyFactory()\n",
    "ont = ofactory.create(\"GO\").subontology(relations=['subClassOf', PART_OF])\n",
    "\n",
    "afactory = AssociationSetFactory()\n",
    "aset = afactory.create(ontology=ont,\n",
    "                       subject_category='gene',\n",
    "                       object_category='function',\n",
    "                       taxon=HUMAN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8500fc81-87b2-4128-8c49-f6e03d603920",
   "metadata": {},
   "source": [
    "### Metric definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0b6dc77e-2029-4c38-9f19-adb21bf34763",
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection(lst1, lst2):\n",
    "    return list(set(lst1) & set(lst2))\n",
    "\n",
    "def metric_based_on_information_theory(cluster):\n",
    "    counter = 0\n",
    "    result = 0\n",
    "    size_of_cluster = len(cluster)\n",
    "    for i in range(size_of_cluster):\n",
    "        for j in range(i + 1, size_of_cluster):\n",
    "            goTerms = intersection(ont.ancestors(cluster[i]),ont.ancestors(cluster[j]))\n",
    "            minimum_infromation_metric = 1\n",
    "            for goTerm in goTerms:\n",
    "                infromation_metric = nodeDict[goTerm].infromationMetric\n",
    "                if minimum_infromation_metric > infromation_metric:\n",
    "                    minimum_infromation_metric = infromation_metric\n",
    "                    \n",
    "                \n",
    "            result -= math.log(minimum_infromation_metric)\n",
    "            counter +=1\n",
    "    if counter == 0 :\n",
    "        return 0\n",
    "    return result/counter\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "57850945-f6e7-4053-bbfb-71a86e484191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1850\n",
      "1.2069340203196353\n",
      "1\n",
      "0\n",
      "34\n",
      "1.1823104417124188\n",
      "20\n",
      "1.321660142019698\n",
      "413\n",
      "1.2737437458400729\n",
      "3\n",
      "1.0454587994088804\n",
      "23\n",
      "1.3539160093099825\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i in clustersGO:\n",
    "    print(metric_based_on_information_theory(i) )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83970699-c862-418e-a6f3-3e982a0b7029",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
